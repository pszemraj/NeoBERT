"""RMSNorm layer implementation."""

import torch
from torch import nn


class RMSNorm(nn.Module):
    """Root-mean-square normalization layer."""

    def __init__(self, dim: int, eps: float = 1e-6) -> None:
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Accumulate in float32 for numerical stability, then cast back.
        x_float = x.float()
        rms = torch.rsqrt(x_float.pow(2).mean(-1, keepdim=True) + self.eps)
        return (x_float * rms).to(x.dtype) * self.weight
