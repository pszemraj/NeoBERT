task: "pretraining"

model:
  hidden_size: 1536
  num_hidden_layers: 28
  num_attention_heads: 12
  intermediate_size: 6144
  dropout_prob: 0.0
  vocab_size: 31999
  max_position_embeddings: 4096
  attn_backend: flash_attn_varlen
  kernel_backend: auto
  ngpt: false
  hidden_act: "swiglu"
  rope: true
  rms_norm: true

dataset:
  name: "EleutherAI/SmolLM2-1.7B-stage-4-100B"
  streaming: true
  num_proc: 8
  num_workers: 4
  max_seq_length: 1024
  train_split: "train"
  eval_split: null
  eval_samples: 4096

tokenizer:
  name: "BEE-spoke-data/wordpiece-tokenizer-32k-en_code-msp"
  vocab_size: 31999
  max_length: 1024
  truncation: true

datacollator:
  mlm_probability: 0.2
  mask_all: false
  pad_to_multiple_of: 8
  pack_sequences: true

trainer:
  output_dir: "./outputs/neobert-fp8-muon-fsdp2-no-shard-4gpu"
  max_steps: 100000
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 4
  enforce_full_packed_batches: true
  logging_steps: 25
  log_train_accuracy: false
  log_grad_norm: true
  log_weight_norms: true
  eval_steps: 5000
  save_steps: 5000
  save_total_limit: 3
  mixed_precision: "fp8"
  torch_compile: true
  torch_compile_backend: "inductor"
  fp8:
    recipe: "tensorwise"
    filter_fqns: []
    auto_filter_small_kn: false
    enable_fsdp_float8_all_gather: true
    pad_inner_dim: true
    use_regional_compilation: true
  masked_logits_only_loss: true
  gradient_checkpointing: false
  resume_from_checkpoint: false

optimizer:
  name: "muonclip"
  lr: 1e-4
  weight_decay: 0.01
  betas: [0.9, 0.95]
  eps: 1e-8
  muon_config:
    orthogonalization: polar_express
    muon_beta: 0.95
    muon_decay: 0.01
    ns_steps: 5
    enable_clipping: true
    clipping_threshold: 50.0
    clipping_alpha: 0.5
    clipping_warmup_steps: 0
    clipping_interval: 10
    clipping_qk_chunk_size: 1024
    capture_last_microbatch_only: true
    detect_anomalies: false
    clipping_layers_mapping: {}

scheduler:
  name: "cosine"
  warmup_steps: 5000
  total_steps: 100000

wandb:
  enabled: true
  project: "neobert-pretraining"
  name: "neobert-fp8-muon-fsdp2-no-shard-4gpu"
  mode: "online"

seed: 69
