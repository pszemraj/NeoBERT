# Test configuration for SmolLM2 streaming with 200 steps

task: pretraining

dataset:
  name: "EleutherAI/SmolLM2-1.7B-stage-4-100B"
  train_split: "train"
  streaming: true
  num_workers: 0
  max_seq_length: 2048

# Model configuration (small model for testing)
model:
  hidden_size: 512
  num_hidden_layers: 8
  num_attention_heads: 8
  intermediate_size: 2048
  hidden_act: "swiglu"
  xformers_attention: true
  max_position_embeddings: 2048  # SmolLM2 uses longer sequences

tokenizer:
  name: "bert-base-uncased"
  max_length: 2048

# Training configuration
trainer:
  output_dir: "outputs/smollm2_test"
  max_steps: 200
  gradient_accumulation_steps: 4
  mixed_precision: "bf16"
  save_steps: 50
  logging_steps: 10
  disable_tqdm: false
  eval_steps: 500
  tf32: true

# Collator configuration
datacollator:
  mlm_probability: 0.15
  pad_to_multiple_of: 8
  mask_all: false
  pack_sequences: false
  max_length: 2048  # Match model max length

# Optimizer configuration
optimizer:
  name: "adamw"
  lr: 5e-5
  betas: [0.9, 0.999]
  eps: 1e-8
  weight_decay: 0.01

# Scheduler configuration
scheduler:
  name: "cosine"
  warmup_steps: 20
  total_steps: 200
  final_lr_ratio: 0.1

# Wandb configuration
wandb:
  resume: never
  name: "smollm2-streaming-test"
  project: "neo-bert"
  entity: null
  tags: ["streaming", "smollm2", "test"]
  dir: "logs/wandb"
  mode: disabled

# Random seed
seed: 42
