task: pretraining

dataset:
  name: "common-pile/comma_v0.1_training_dataset"
  train_split: "train"
  eval_split: "validation"
  streaming: true
  num_workers: 0  # Required for streaming datasets to avoid pickling errors

model:
  dropout_prob: 0.0
  attn_backend: sdpa

tokenizer:
  path: "google-bert/bert-base-uncased"
  max_length: 512
  padding: "max_length"
  truncation: true

trainer:
  output_dir: "./outputs/streaming_test"
  max_steps: 100
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 1
  save_steps: 50
  eval_steps: 50
  logging_steps: 10
  gradient_checkpointing: false
  mixed_precision: "bf16"
  report_to: []  # Disable wandb
  dataloader_num_workers: 0
  gradient_clipping: 1.0

optimizer:
  name: "adamw"
  lr: 5.0e-5
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

scheduler:
  name: "linear"
  warmup_steps: 10

datacollator:
  mlm_probability: 0.15
